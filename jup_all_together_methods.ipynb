{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        data = pickle.load(f) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод Луна: поиск наиболее частых слов\n",
    "def choose_most_freq_words(bag_of_words):\n",
    "    freq = bag_of_words.sum(axis=0)  # подсчет частоты каждого слова\n",
    "    sort_freq_index = np.argsort(freq)\n",
    "    top_words_index = sort_freq_index[-int(len(freq) / 10):]  # 10% наиболее частых\n",
    "    return top_words_index\n",
    "\n",
    "# Метод Луна: подсчет ранга предложений\n",
    "def count_range_sentences(bag_of_words, top_words_index):\n",
    "    sent_range_list = []\n",
    "    for i, sent in enumerate(bag_of_words):  # take word-index string\n",
    "        use_words_index = np.nonzero(sent)  \n",
    "        words_count = len(use_words_index)\n",
    "        top_words_count = len(np.intersect1d(top_words_index, use_words_index))\n",
    "\n",
    "        sent_range = (top_words_count ** 2) / words_count\n",
    "        sent_range_list.append(sent_range)\n",
    "    return sent_range_list\n",
    "\n",
    "# Метод Луна: выбор предложений для аннотации\n",
    "def choose_sent_for_summ(sent_range_list, y_sent_count):\n",
    "    sort_sent_range = np.argsort(sent_range_list)\n",
    "    sent_for_summ_index = np.sort(sort_sent_range[-y_sent_count:]) \n",
    "    return sent_for_summ_index\n",
    "\n",
    "# Метод Луна\n",
    "def method_Luhn(tfidf_texts_X, count_sent_in_text_Y):\n",
    "    index_sent_for_summ = []\n",
    "\n",
    "    for i, tfidf_text in tqdm(enumerate(tfidf_texts_X)):\n",
    "        tfidf_text = tfidf_text.toarray()\n",
    "        top_words_index = choose_most_freq_words(tfidf_text)\n",
    "        sent_range_list = count_range_sentences(tfidf_text, top_words_index)\n",
    "        sent_for_summ_index = choose_sent_for_summ(sent_range_list, count_sent_in_text_Y[i])\n",
    "        index_sent_for_summ.append(sent_for_summ_index)\n",
    "    return index_sent_for_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классификация: обучение модели с валидацией\n",
    "def tree_model_training(X_train, Y_train, X_val, Y_val):\n",
    "    xgb_params = {'eta': 0.2, \n",
    "              'max_depth': 8, \n",
    "              'subsample': 0.6, \n",
    "              'colsample_bytree': 0.7, \n",
    "              'objective': 'binary:logistic', \n",
    "              'eval_metric': 'logloss', \n",
    "              }\n",
    "    num_rounds = 200\n",
    "    d_train = xgb.DMatrix(X_train, Y_train)\n",
    "    d_val = xgb.DMatrix(X_val, Y_val)\n",
    "    evallist = [(d_val, 'val')]\n",
    "\n",
    "    model_xgb = xgb.train(xgb_params, d_train, num_rounds, evallist, early_stopping_rounds=10)\n",
    "    return model_xgb\n",
    "\n",
    "# Классификация: получение предсказания модели и выбор предложений для аннотации\n",
    "def tree_predict(model, X_test, count_sent_Y_test):\n",
    "    d_test = xgb.DMatrix(X_test)\n",
    "    Y_predict = model.predict(d_test, iteration_range=(0, my_model.best_iteration))\n",
    "    \n",
    "    index_sent_for_summ = []\n",
    "    new_text_start = 0\n",
    "    for text_ind in tqdm(range(len(count_sent_X_test))):\n",
    "        text_end = new_text_start + count_sent_X_test[text_ind]\n",
    "        predict_for_one_text = Y_predict[new_text_start : text_end]\n",
    "        sort_index = np.argsort(predict_for_one_text)[::-1] \n",
    "        # выбираем с наибольшим предсказанием\n",
    "        index_sent_for_summ.append(sort_index[:count_sent_Y_test[text_ind]])  \n",
    "        new_text_start = text_end  \n",
    "    return index_sent_for_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация: выбор предложений для аннотации\n",
    "def clustering(tfidf_texts_X, count_sent_in_text_Y):\n",
    "    index_sent_for_summ = []\n",
    "    new_text_start = 0\n",
    "    for i, text in tqdm(enumerate(tfidf_texts_X)):\n",
    "        cluster_count = count_sent_in_text_Y[i]\n",
    "\n",
    "        model_km = KMeans(n_clusters = cluster_count)\n",
    "        cluster_field = model_km.fit(text)\n",
    "        distance_to_cluster = model_km.transform(text)\n",
    "\n",
    "        sent_ind_close_centroids = np.argmin(distance_to_cluster, axis=0)\n",
    "        index_sent_for_summ.append(sent_ind_close_centroids)\n",
    "    return index_sent_for_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-poster",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tfidf_texts_X_test = load_from('file_name.pickle')\n",
    "    count_sent_in_text_Y_test = load_from('file_name.pickle')\n",
    "    tfidf_sents_X_train = load_from('file_name.pickle')\n",
    "    tfidf_sents_Y_train = load_from('file_name.pickle')\n",
    "    tfidf_sents_X_val = load_from('file_name.pickle')\n",
    "    tfidf_sents_Y_val = load_from('file_name.pickle')\n",
    "    tfidf_sents_X_test = load_from('file_name.pickle')\n",
    "    \n",
    "    # Получение индексов предложений для аннотации по методу Луна\n",
    "    Luhn_index_sent_for_summ = method_Luhn(tfidf_texts_X_test, count_sent_in_text_Y_test)\n",
    "    \n",
    "    # Обучение модели классификатора\n",
    "    classif_model = Tree_model_training(\n",
    "        tfidf_sents_X_train, tfidf_sents_Y_train, tfidf_sents_X_val, tfidf_sents_Y_val\n",
    "    )\n",
    "    # Получение индексов предложений для аннотации по методу классификации\n",
    "    Tree_index_sent_for_summ = Tree_predict(\n",
    "        classif_model, tfidf_sents_X_test, count_sent_in_text_Y_test\n",
    "    )\n",
    "    \n",
    "    # Получение индексов предложений для аннотации по методу кластеризации\n",
    "    Cluster_index_sent_for_summ = clustering(tfidf_texts_X_test, count_sent_in_text_Y_test)\n",
    "    \n",
    "    # сохранение результатов работы методов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
