{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selected-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enabling-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(file):\n",
    "    with open(file, \"r\", encoding='utf-8') as f:\n",
    "        json_list = list(f)\n",
    "\n",
    "    all_news_text_X = []\n",
    "    all_news_summ_Y = []\n",
    "    for i, str in enumerate(json_list):\n",
    "        one_news = json.loads(str)\n",
    "        del one_news['url']\n",
    "        del one_news['title']\n",
    "        del one_news['date']\n",
    "        all_news_text_X.append(one_news['text'])\n",
    "        all_news_summ_Y.append(one_news['summary'])\n",
    "    return all_news_text_X, all_news_summ_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuck-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(vec_X, vec_Y):\n",
    "    # count angle between center vectors\n",
    "    vec_X_unit = (vec_X / np.linalg.norm(vec_X)) if np.linalg.norm(vec_X) != 0 else np.zeros(vec_X.shape)\n",
    "    vec_Y_unit = (vec_Y / np.linalg.norm(vec_Y)) if np.linalg.norm(vec_Y) != 0 else np.zeros(vec_Y.shape)\n",
    "    angles = np.arccos(np.clip(np.dot(vec_X_unit, vec_Y_unit), -1.0, 1.0))\n",
    "    # привожу [0 - хорошо, pi/2 - плохо] к [0 - плохо, 1 - хорошо]\n",
    "    score_01 = 1 - (angles / (np.pi/2))\n",
    "    return score_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "по предсказанным индексам доставать предложения из Х\n",
    "посчитать s для каждого с каждым из Х и Y (для 1 текста) (score - доля совпадения от 0 до 1)\n",
    "для каждого предложения Y взять предложение Х с максимальным score (каждое предложение только 1 раз)\n",
    "итоговая оценка метода - среднее от суммы выбранных score\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "invisible-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_best_scores_texts(index_sent_for_summ):\n",
    "    all_best_scores_text = [] # средний score по текстам\n",
    "    \n",
    "    for text_i in tqdm(range(len(X_tfidf_texts_test))):\n",
    "        sent_X = X_tfidf_texts_test[text_i].toarray()\n",
    "        sent_for_summ_predict = sent_X[index_sent_for_summ[text_i]]\n",
    "        sent_for_summ_real = Y_tfidf_texts_test[text_i].toarray()\n",
    "    \n",
    "        best_scores_sent_this_text = []\n",
    "        can_be_choosed_Y = np.zeros(len(sent_for_summ_real), dtype=bool)  # маска индексов Y , кот еще участвуют\n",
    "        for vec_x in sent_for_summ_predict:\n",
    "            all_scores = np.ma.array([score(vec_x, vec_y) for vec_y in sent_for_summ_real], mask=can_be_choosed_Y)\n",
    "            best_scores_sent_this_text.append(np.max(all_scores))\n",
    "            can_be_choosed_Y[np.argmax(all_scores)] = True\n",
    "\n",
    "        all_best_scores_text.append(np.sum(best_scores_sent_this_text)/len(best_scores_sent_this_text))\n",
    "            \n",
    "    return all_best_scores_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-liver",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "possible-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tree_index_sent_for_summ_X_test.pickle', 'rb') as f:\n",
    "    index_sent_for_summ_tree = pickle.load(f)\n",
    "with open('cluster_index_sent_for_summ_X_test.pickle', 'rb') as f:\n",
    "    index_sent_for_summ_cluster = pickle.load(f)\n",
    "with open('luhn_index_sent_for_summ_X_test.pickle', 'rb') as f:\n",
    "    index_sent_for_summ_luhn = pickle.load(f)\n",
    "with open('X_tfidf_texts_test.pickle', 'rb') as f:\n",
    "    X_tfidf_texts_test = pickle.load(f)\n",
    "with open('Y_tfidf_texts_test.pickle', 'rb') as f:\n",
    "    Y_tfidf_texts_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "announced-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sent_for_summ_tree = np.array(index_sent_for_summ_tree)\n",
    "index_sent_for_summ_cluster = np.array(index_sent_for_summ_cluster)\n",
    "index_sent_for_summ_luhn = np.array(index_sent_for_summ_luhn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "buried-dallas",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0256729249130353, 0.23405374259176293] 0.1298633337523991\n",
      "[0.014928072858538477, 0.04887725878243421, 0.028656235827061782, 0.0] 0.023115391867008617\n",
      "[0.09169394370732253, 0.20149708639183228, 0.0] 0.09773034336638493\n",
      "[0.1730294088288037, 0.06077029450631022, 0.22036702911778272] 0.1513889108176322\n",
      "[0.06442388652740794, 0.045408794964422405, 0.03253794465899407] 0.047456875383608134\n",
      "[0.21689010281838395, 0.0, 0.2668812218317862, 0.11035106242014092] 0.14853059676757777\n",
      "[0.061023845310278935, 0.0, 0.040427320830862645] 0.033817055380380524\n",
      "[0.0963364625340708, 0.03862140205980946, 0.0] 0.044985954864626754\n",
      "[0.08682707525142686, 0.12875702987823645, 0.0, 0.0] 0.053896026282415826\n",
      "[0.08128701129188898, 0.0, 0.015187717885166818] 0.0321582430590186\n",
      "[0.0, 0.015232688131658678] 0.007616344065829339\n",
      "[0.023029613449763953] 0.023029613449763953\n",
      "[0.13243929972869173, 0.0] 0.06621964986434586\n",
      "[0.037097404407835044, 0.04887725878243421, 0.0, 0.0] 0.021493665797567313\n",
      "[0.0, 0.20149708639183228, 0.0] 0.06716569546394409\n",
      "[0.2565168401835308, 0.013349228480949438, 0.21719783448278418] 0.16235463438242148\n",
      "[0.1362179696463358, 0.0, 0.0] 0.04540598988211194\n",
      "[0.05325072746625059, 0.04446557622253111, 0.07977537491826858, 0.0] 0.04437291965176257\n",
      "[0.26089504439939326, 0.0, 0.0] 0.08696501479979775\n",
      "[0.22797063195954714, 0.0, 0.0] 0.07599021065318239\n",
      "[0.0674223939920946, 0.07736822837583202, 0.08235678992651929, 0.0] 0.056786853073611476\n",
      "[0.042354576781721276, 0.2656214440904001, 0.0] 0.10265867362404046\n",
      "[0.10857695125039657, 0.1289403909965302] 0.11875867112346339\n",
      "[0.10718029586163036] 0.10718029586163036\n",
      "[0.08692919579534475, 0.08748000790255317] 0.08720460184894896\n",
      "[0.0808872985971395, 0.11514367456161911, 0.0, 0.0] 0.049007743289689654\n",
      "[0.09169394370732253, 0.13281300240256955, 0.0] 0.07483564870329736\n",
      "[0.028027153280723804, 0.046537059288218496, 0.019430892829170987] 0.031331701799371094\n",
      "[0.06442388652740794, 0.0888634786424859, 0.045408794964422405] 0.06623205337810541\n",
      "[0.29645028646156124, 0.14345088686597685, 0.024699526212254352, 0.0] 0.11615017488494811\n",
      "[0.061769210225976035, 0.05036332436151403, 0.011167626524549057] 0.04110005370401304\n",
      "[0.04307964623335192, 0.0, 0.03862140205980946] 0.02723368276438713\n",
      "[0.03880112774160427, 0.12247327746335712, 0.05886837189684779, 0.0] 0.055035694275452296\n",
      "[0.11836549420624953, 0.04023420891163243, 0.0] 0.052866567705960654\n",
      "[0.1444071737790691, 0.0] 0.07220358688953454\n",
      "[0.046743233215368996] 0.046743233215368996\n"
     ]
    }
   ],
   "source": [
    "all_best_scores_text_tree = calc_best_scores_texts(index_sent_for_summ_tree)\n",
    "all_best_scores_text_cluster = calc_best_scores_texts(index_sent_for_summ_cluster)\n",
    "all_best_scores_text_luhn = calc_best_scores_texts(index_sent_for_summ_luhn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extended-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_best_scores_text_tree.pickle', 'wb') as f:\n",
    "    pickle.dump(all_best_scores_text_tree, f)\n",
    "with open('all_best_scores_text_cluster.pickle', 'wb') as f:\n",
    "    pickle.dump(all_best_scores_text_cluster, f)\n",
    "with open('all_best_scores_text_luhn.pickle', 'wb') as f:\n",
    "    pickle.dump(all_best_scores_text_luhn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conditional-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08870041045497278\n",
      "0.09278036692290285\n",
      "0.09100806481352615\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(all_best_scores_text_tree)/len(all_best_scores_text_tree))\n",
    "print(np.sum(all_best_scores_text_cluster)/len(all_best_scores_text_cluster))\n",
    "print(np.sum(all_best_scores_text_luhn)/len(all_best_scores_text_luhn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "popular-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6172737639590911\n",
      "0.7771379789725386\n",
      "0.5656863302557644\n",
      "1411\n",
      "582\n",
      "3965\n"
     ]
    }
   ],
   "source": [
    "print(np.max(all_best_scores_text_tree))\n",
    "print(np.max(all_best_scores_text_cluster))\n",
    "print(np.max(all_best_scores_text_luhn))\n",
    "\n",
    "print(np.argmax(all_best_scores_text_tree))\n",
    "print(np.argmax(all_best_scores_text_cluster))\n",
    "print(np.argmax(all_best_scores_text_luhn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-attitude",
   "metadata": {},
   "source": [
    "### Получение текста и его аннотации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designing-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news_text_X, all_news_summ_Y = unpack(\n",
    "    'C:/Users/Acer/PycharmProjects/ML_NLP_course3/gazeta_jsonl/gazeta_test.jsonl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opposed-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tree_index_sent_for_summ_X_test.pickle', 'rb') as f:\n",
    "    index_sent_for_summ_tree = pickle.load(f)\n",
    "with open('cluster_index_sent_for_summ_X_test.pickle', 'rb') as f:\n",
    "    index_sent_for_summ_cluster = pickle.load(f)\n",
    "with open('luhn_index_sent_for_summ_X_test.pickle', 'rb') as f:\n",
    "    index_sent_for_summ_luhn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "potential-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_best_scores_text_tree.pickle', 'rb') as f:\n",
    "    all_best_scores_text_tree = pickle.load(f)\n",
    "with open('all_best_scores_text_cluster.pickle', 'rb') as f:\n",
    "    all_best_scores_text_cluster = pickle.load(f)\n",
    "with open('all_best_scores_text_luhn.pickle', 'rb') as f:\n",
    "    all_best_scores_text_luhn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "given-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin([a for a in all_best_scores_text_cluster[45:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bound-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(np.array([len(nltk.sent_tokenize(text)) for text in all_news_text_X])))\n",
    "print(np.min(np.array([len(nltk.sent_tokenize(text)) for text in all_news_text_X])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "outstanding-antenna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[10 13]\n"
     ]
    }
   ],
   "source": [
    "text_index = 48\n",
    "print(all_best_scores_text_cluster[text_index])\n",
    "text_X_indexes_summ = np.sort(index_sent_for_summ_cluster[text_index])\n",
    "print(text_X_indexes_summ)\n",
    "text_X = all_news_text_X[text_index]\n",
    "text_X_token = nltk.sent_tokenize(text_X)\n",
    "text_Y = all_news_summ_Y[text_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "running-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст\n",
      "Ведущий популярного телешоу «Караоке в машине» Джеймс Корден прокомментировал недавний скандал со своим участием, когда пользователи интернета уличили его в том, что в действительности не он водит автомобиль во время съемок своей передачи. Видеообращение Кордена было опубликовано на YouTube-канале «The Late Late Show with James Corden». Телеведущий начал с того, что назвал неправдой все обвинения в свой адрес. Далее он продемонстрировал видео, которое попало несколько дней назад в Twitter. На нем видно, что Корден и поп-звезда Джастин Бибер едут в машине, на которой установлен специальный прицеп, и ее везет грузовик. «Я знаю — это выглядит плохо, — сказал знаменитый англичанин, выдержав драматическую паузу. — Но я просто хочу сказать сейчас, что я всегда сам вожу машину, пока мы не делаем что-то, что может показаться небезопасным. Например, танцы, смена костюмов или если я пьян». Что касается ситуации с Бибером , по словам ведущего, решение воспользоваться страховкой было принято из соображений безопасности, поскольку он боялся «опростоволоситься» в присутствии молодого исполнителя. Далее Корден отметил, что «разоблачительный ролик» собрал более 14 млн просмотров, тогда как сами выпуски «Караоке в машине» не могут похвастаться подобным вниманием зрителей. После этого ведущий привел в пример несколько заголовков в крупных СМИ: «Джеймс Корден был разоблачен в вирусном твите, который показывает, что он на самом деле не водит автомобиль в «Караоке в машине»», «Разбивающее мечты откровение о «Караоке в машине»», «Худшая ложь со времен Санты». Кроме того, шоумен пошутил, что шокирован тем, что «сделал что-то, расстроившее людей больше, чем фильм «Кошки». По словам Кордена, он был поражен, сколь рьяно пользователи соцсетей набросились на него. «Вот почему я не доверяю людям», «С меня хватит этого вранья», «Вся моя жизнь была ложью», «2020 уже научил меня тому, что верить нельзя никому», — сокрушались англоязычные пользователи Twitter. Особое внимание телеведущий уделил пользователю c ником Assgaze («Пристальный взгляд из задницы» — англ.), который назвал его «гребаным лгуном». «Есть люди, с кем я мог быть не до конца честен, но я никогда не солгал бы Assgaze», — подчеркнул комик. Затем Корден поклялся зрителям, что в 95% случаев он действительно «подвергает опасности» жизни величайших мировых поп-звезд. «Но это телешоу, и не все в нем реально. Наша передача никогда не снимается в полночь, мы снимаем его в 5 вечера и притворяемся, что сейчас поздно, — продолжил шоумен. — Мне казалось, что такие простые вещи и так все знают. Я сожалею, что вы так глубоко погрузились в реальность «Караоке в машине», но это телевидение и мы часто делаем вещи только ради развлечения». В конце своей речи Корден предложил зрителям посмотреть новый сезон передачи, где все «действительно сами водят машину, кроме тех моментов, когда они этого не делают».\n",
      "\n",
      "Оригинальная аннотация\n",
      "Телеведущий Джеймс Корден оправдался перед зрителями за появившийся в сети ролик, на котором видно, что в рамках «Караоке в машине» шоумен вместе с поп-исполнителем Джастином Бибером едут в автомобиле, который на самом деле везет грузовик. Комик заверил, что подобное скорее является исключением из правил ради безопасности.\n",
      "\n",
      "Сгенерированная аннотация\n",
      "После этого ведущий привел в пример несколько заголовков в крупных СМИ: «Джеймс Корден был разоблачен в вирусном твите, который показывает, что он на самом деле не водит автомобиль в «Караоке в машине»», «Разбивающее мечты откровение о «Караоке в машине»», «Худшая ложь со времен Санты». «Вот почему я не доверяю людям», «С меня хватит этого вранья», «Вся моя жизнь была ложью», «2020 уже научил меня тому, что верить нельзя никому», — сокрушались англоязычные пользователи Twitter.\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст\")\n",
    "print(text_X + '\\n')\n",
    "print(\"Оригинальная аннотация\")\n",
    "print(all_news_summ_Y[text_index] + '\\n')\n",
    "print(\"Сгенерированная аннотация\")\n",
    "print(\" \".join([text_X_token[index_summ] for index_summ in text_X_indexes_summ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comic-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i<50:\n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
