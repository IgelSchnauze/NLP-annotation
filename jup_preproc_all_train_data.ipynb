{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mexican-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "# from string import punctuation\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuous-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(file):\n",
    "    with open(file, \"r\", encoding='utf-8') as f:\n",
    "        json_list = list(f)\n",
    "\n",
    "    all_news_text_X = []\n",
    "    all_news_summ_Y = []\n",
    "    for i, str in enumerate(json_list):\n",
    "        one_news = json.loads(str)\n",
    "        del one_news['url']\n",
    "        del one_news['title']\n",
    "        del one_news['date']\n",
    "        all_news_text_X.append(one_news['text'])\n",
    "        all_news_summ_Y.append(one_news['summary'])\n",
    "    return all_news_text_X, all_news_summ_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "african-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_list(list, delimiter):\n",
    "    splitted = [[]]\n",
    "    for lemma in list:\n",
    "        if lemma == delimiter:\n",
    "            splitted.append([])\n",
    "        else:\n",
    "            splitted[-1].append(lemma)\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unavailable-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_str, punctuation_re):\n",
    "    mystem = Mystem()\n",
    "    rus_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "    text_lemmas = mystem.lemmatize(text_str.lower())\n",
    "    text_lemmas = [punctuation_re.sub('', lemma) for lemma in text_lemmas ] # удаляю все кроме букв и цифр\n",
    "    text_lemmas = [lemma for lemma in text_lemmas if lemma.strip() != '' and lemma not in rus_stopwords]\n",
    "\n",
    "    return text_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "english-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_bag_words_make_vocab(all_sent_list):\n",
    "    tf_vectorizer = TfidfVectorizer(max_features=50000, max_df=0.85)  # слово встречается > чем в 85% -> не берем\n",
    "\n",
    "    all_sent_str = [\" \".join(one_sent_list) for one_sent_list in all_sent_list]  # список из предложений=строк\n",
    "    bag_of_words = tf_vectorizer.fit_transform(all_sent_str)\n",
    "    vocabulary = tf_vectorizer.get_feature_names()\n",
    "    return bag_of_words, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "anticipated-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(vec_X, vec_Y):\n",
    "    # count angle between center vectors\n",
    "    vec_X_unit = (vec_X / np.linalg.norm(vec_X)) if np.linalg.norm(vec_X) != 0 else np.zeros(vec_X.shape)\n",
    "    vec_Y_unit = (vec_Y / np.linalg.norm(vec_Y)) if np.linalg.norm(vec_Y) != 0 else np.zeros(vec_Y.shape)\n",
    "    angles = np.arccos(np.clip(np.dot(vec_X_unit, vec_Y_unit), -1.0, 1.0))\n",
    "    # привожу [0 - хорошо, pi/2 - плохо] к [0 - плохо, 1 - хорошо]\n",
    "    score_01 = 1 - (angles / (np.pi/2))\n",
    "    return score_01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-threshold",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "criminal-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news_text_X, all_news_summ_Y = unpack(\n",
    "        'C:/Users/Acer/PycharmProjects/ML_NLP_course3/gazeta_jsonl/gazeta_train.jsonl')\n",
    "# my_punctuation = punctuation + '–' + '—' + '«' + '»' + '», —' + '%, ' + '» — ' + ': «' + '» (' + '), ' + ', «'\n",
    "punctuation_re = re.compile('[^a-zA-Zа-яА-Я0-9]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "limiting-command",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "52400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-bd6333328061>:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  all_preproc_sent_text_X = np.array(all_preproc_sent_text_X)\n"
     ]
    }
   ],
   "source": [
    "all_preproc_sent_text_X = []\n",
    "count_sent_in_text_X = []\n",
    "pack_size = 1000\n",
    "start_ind = 0  # to count start new 1000 text pack\n",
    "while start_ind < len(all_news_text_X):\n",
    "#     # временное ограничение!!!!\n",
    "#     if start_ind >= 6:\n",
    "#         break\n",
    "    \n",
    "    # join and preprocessing\n",
    "    pack_list_for_preproc = []\n",
    "    end_ind = start_ind + pack_size\n",
    "    if end_ind > len(all_news_text_X):\n",
    "        end_ind = len(all_news_text_X)\n",
    "        \n",
    "    for i in range(start_ind, end_ind):\n",
    "        sentences = nltk.sent_tokenize(all_news_text_X[i])\n",
    "        count_sent_in_text_X.append(len(sentences))\n",
    "        pack_list_for_preproc.append(' bbreakk '.join(sentences))  # between sentences 'bbreakk'\n",
    "    pack_str_for_preproc = ' bbreakk '.join(pack_list_for_preproc)\n",
    "    pack_lemmas = preprocess(pack_str_for_preproc, punctuation_re)\n",
    "\n",
    "    # split\n",
    "    preproc_sentences = spliting_list(pack_lemmas, 'bbreakk') # список из предложений=строк\n",
    "    all_preproc_sent_text_X.extend(preproc_sentences)\n",
    "    \n",
    "    start_ind += pack_size\n",
    "    print(end_ind)\n",
    "    \n",
    "    if sum(count_sent_in_text_X) != len(all_preproc_sent_text_X):\n",
    "        print('error')\n",
    "        break\n",
    "    \n",
    "count_sent_in_text_X = np.array(count_sent_in_text_X)    \n",
    "all_preproc_sent_text_X = np.array(all_preproc_sent_text_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "impossible-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_preproc_sent_text_X.pickle', 'wb') as f:\n",
    "    pickle.dump(all_preproc_sent_text_X, f)\n",
    "with open('count_sent_in_text_X.pickle', 'wb') as f:\n",
    "    pickle.dump(count_sent_in_text_X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "statistical-wayne",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "52400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-be508767569f>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  all_preproc_sent_summ_Y = np.array(all_preproc_sent_summ_Y)\n"
     ]
    }
   ],
   "source": [
    "all_preproc_sent_summ_Y = []\n",
    "count_sent_in_summ_Y = []\n",
    "pack_size = 1000\n",
    "start_ind = 0  # to count start new 1000 text pack\n",
    "while start_ind < len(all_news_summ_Y):\n",
    "#     # временное ограничение!!!!\n",
    "#     if start_ind >= 6:\n",
    "#         break\n",
    "    \n",
    "    # join and preprocessing\n",
    "    pack_list_for_preproc = []\n",
    "    end_ind = start_ind + pack_size\n",
    "    if end_ind > len(all_news_summ_Y):\n",
    "        end_ind = len(all_news_summ_Y)\n",
    "        \n",
    "    for i in range(start_ind, end_ind):\n",
    "        sentences = nltk.sent_tokenize(all_news_summ_Y[i])\n",
    "        count_sent_in_summ_Y.append(len(sentences))\n",
    "        pack_list_for_preproc.append(' bbreakk '.join(sentences))  # between sentences '<break>'\n",
    "    pack_str_for_preproc = ' bbreakk '.join(pack_list_for_preproc)\n",
    "    pack_lemmas = preprocess(pack_str_for_preproc, punctuation_re)\n",
    "\n",
    "    # split\n",
    "    preproc_sentences = spliting_list(pack_lemmas, 'bbreakk') # список из предложений=строк\n",
    "    all_preproc_sent_summ_Y.extend(preproc_sentences)\n",
    "    \n",
    "    start_ind += pack_size\n",
    "    print(end_ind)\n",
    "    \n",
    "    if sum(count_sent_in_summ_Y) != len(all_preproc_sent_summ_Y):\n",
    "        print('error')\n",
    "        break\n",
    "    \n",
    "count_sent_in_summ_Y = np.array(count_sent_in_summ_Y)    \n",
    "all_preproc_sent_summ_Y = np.array(all_preproc_sent_summ_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "laughing-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_preproc_sent_summ_Y.pickle', 'wb') as f:\n",
    "    pickle.dump(all_preproc_sent_summ_Y, f)\n",
    "with open('count_sent_in_summ_Y.pickle', 'wb') as f:\n",
    "    pickle.dump(count_sent_in_summ_Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "improved-possibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "надо обработанные тексты Х У объединить, чтобы сделать общий мешок слов\n",
    "потом разделить обратно, но каждое предложение будет выглядеть как вектор tf-idf из всеех слов всех текстов и аннотаций\n",
    "'''\n",
    "all_sent = np.concatenate((all_preproc_sent_text_X, all_preproc_sent_summ_Y), axis=None)\n",
    "tfidf_all_sent, train_vocabulary = tfidf_bag_words_make_vocab(all_sent)\n",
    "print(len(train_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "stopped-saturday",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cnn' 's4' 'юрский' 'торстен' 'обманщик' 'склонение' 'подобие' 'привычно'\n",
      " 'императорский' 'сцепляться' 'q5' 'позавчерашний' 'недорост'\n",
      " 'дефибриллятор' 'подлинно' 'демограф' 'тальявенто' 'запасник' 'погорилый'\n",
      " 'флери' 'состряпать' 'коровин' 'искривлять' 'калий' 'кб' 'cw' 'тритэ'\n",
      " 'изыскивать' 'дипотношение' 'червенок' 'битцевский' 'приставание'\n",
      " 'министерский' 'конобрий' 'воспроизводство' 'перезаключение'\n",
      " 'всматриваться' 'долгожданный' 'оккупационный' 'структурировать'\n",
      " 'сенаторзой' 'залив' 'имэмо' 'преемница' 'фара' 'масальскис'\n",
      " 'невозвратный' 'мифический' 'повторный' 'убавляться' 'сбыт' 'олигархия'\n",
      " 'неспособность' 'рукопашная' 'корректно' 'парамонов' 'драгич' 'федерация'\n",
      " 'жена' 'ведомо' 'пырьев' 'мосгорнаследие' 'or' 'своеобразный'\n",
      " 'фотохостинг' 'самоустранение' 'мышца' 'безнадежно' 'самара' 'смуляна'\n",
      " 'месиво' 'франзен' 'awards' 'никакой' 'малочисленность' 'гринуэй'\n",
      " 'усадьба' 'обкрадывать' 'гарик' 'публично' 'увешать' 'экий' 'ланта'\n",
      " 'донский' 'ассамблея' 'мина' 'пиганович' 'мытье' 'рбк' 'клишина'\n",
      " 'перечислять' 'официантка' 'блуждать' 'мантия' 'берегово' 'class'\n",
      " 'ветеринария' 'полыхать' 'босниец' 'вынести' 'коби' 'возвышенный'\n",
      " 'информированный' 'йогурт' 'шовковский' 'кинофраншиза' 'манфред'\n",
      " 'бряцание' 'марлос' 'поствыборный' 'сдвигаться' 'приковывать' 'live'\n",
      " 'гарсия' 'сталкер' 'инвестирование' 'энергия' 'наркотрафик' 'мерлен'\n",
      " 'взаимозависимость' 'равносильный' 'варна' 'сведение' 'войжицки' 'обет'\n",
      " 'предпоказ' 'бульбово' 'жульнический' 'ртрс' 'пуховик' 'химический'\n",
      " 'поручение' 'стриптизерша' 'стилус' 'бак' 'немирович' 'санья' 'халеп'\n",
      " 'абу' 'косенко' 'возраст' 'воспользоваться' 'клирик' 'цудзихар' 'замысел'\n",
      " 'ипотека' 'оглашение' 'активничать' 'паоло' 'фармацевтический'\n",
      " 'пробуксовка' 'биржа' 'смелость' 'душа' 'kronen' 'мастерица' 'паук'\n",
      " 'дворянство' 'неактуальный' 'очертание' 'снабжение' 'диснеевский' '494'\n",
      " 'джиуджитсу' 'верстаться' 'безотносительно' 'комментировать'\n",
      " 'травматолог' 'biology' 'буклет' 'цб' 'госбумага' 'недуг' 'сатира'\n",
      " 'гевин' 'пресвятой' 'смайл' 'пожалуй' 'апартеид' 'викторианский'\n",
      " 'съемный' 'мах' 'несговорчивость' 'ндс' 'баркли' 'горловка' 'прачечный'\n",
      " 'эквадорский' 'жертва' 'рго' 'чи' 'мемориальный' 'центральноазиатский'\n",
      " 'пропасть' 'шаботовый' 'адеболаджо' 'бедолага' 'наброс' 'выпускной'\n",
      " 'фонтанка' 'бардачок' 'алания' 'рубенс' 'жилкин' 'филдс' 'пуант'\n",
      " 'коннерить' 'спуск' 'рашид' 'черноусова' 'угасание' 'пирло' 'автоматизм'\n",
      " 'методологический' 'нато' 'тарасенко' 'жарский' 'энергоноситель'\n",
      " 'poseidon' 'многозначительно' 'неспешный' 'тельо' 'юцюс' 'очередность'\n",
      " 'размещение' 'кима' 'хачеридя' 'апелляционный' 'рецептурный'\n",
      " 'предопределять' 'перевыборы' 'хертогенбосх' 'вимм' 'конфессиональный'\n",
      " 'турпродукт' 'деликатно' 'оос' 'мефистофель' 'тыс' 'патрон' 'нахбар'\n",
      " 'социальнополитический' 'ариэль' 'внуково' 'тото' 'стюардесса'\n",
      " 'гандбольный' 'администрация' 'вод' 'первобытный' 'ломка' 'аруна'\n",
      " 'свинарчук' 'риа' 'крепс' 'емкость' 'муссолини' 'дотла' '378' 'society'\n",
      " 'андерссон' 'попутчик' 'лоуфорд' 'овчарова' 'удочка' 'хихонец'\n",
      " 'восстание' 'югоосетинский' 'тысячелетие' 'санчез' 'апатия' 'морпех'\n",
      " 'самоотверженный' 'сейсмолог' 'краеведческий' 'череповецкий' 'курьез'\n",
      " 'дежурная' 'перерасход' 'разрешительный' 'рукописный' 'рыбинск'\n",
      " 'непокоренный' 'грузия' 'слабенький' 'демаркация' 'обостряться' 'жильбер'\n",
      " 'формализм' 'попортить' 'пранк' 'мусаева' 'папочка' 'биекс' 'ставрополь'\n",
      " 'корпус' 'изволить' 'game' 'штыль' 'автономность' 'оцеплять' 'ополчаться'\n",
      " 'ганичев' 'шизофрения' 'коппол' 'миллион' 'олимпиакос' 'koobface'\n",
      " 'нагнетаться' '542' 'кузнецов' 'спорадический' 'карлис' 'клеветнический'\n",
      " 'реставрация' 'поцелуй' '510' 'русакова' 'эспоо' 'велосипедный' 'шиит'\n",
      " 'цена' 'гость' 'зареченский' '367' 'имеретинский' 'цэа' 'тоскливый'\n",
      " 'больший' 'баданин' 'обрисовывать' 'адекватный' 'топовый' 'изыскание'\n",
      " 'wsb' 'цветочек' 'внешне' 'мандзюк' 'психотерапия' 'должно' '824' 'хит'\n",
      " 'калининградец' 'сужать' 'перерождение' 'тимощук' 'хомицкий' 'амброзинь'\n",
      " 'провоторов' 'cz' 'крейсерский' 'фархади' 'эм' 'дерево' 'энгель'\n",
      " 'повседневность' '222' 'перезагрузка' 'рассказова' 'приветливый' 'сосо'\n",
      " 'заботливо' 'efe' 'дело' 'проходиться' 'величина' 'odyssey' 'затратный'\n",
      " 'зааплодировать' 'паспорт' 'бахов' 'кончина' 'гринь' 'лч' 'портфолио'\n",
      " 'невоенный' 'сразу' 'коммунарка' 'bird' 'смог' 'любляна' 'охта' 'орельен'\n",
      " 'попгруппа' 'ibm' 'иллюзорный' 'iata' 'сателлит' 'разворовывать' '597'\n",
      " 'кандагар' 'горнодобывающий' 'карякина' 'навигатор' 'клетчатый' 'пецшнер'\n",
      " 'папарацци' 'давать' 'дымиться' 'зурабов' 'обруч' 'комстар' 'машков'\n",
      " 'забрезжить' 'распиливать' 'пашкин' 'лайма' 'тадича' 'инсайдер'\n",
      " 'музейщик' 'можайский' 'смольянин' 'устимчук' 'сабирзян' '176'\n",
      " 'чрезвычайно' 'зепп' 'лучич' 'перевес' 'диснейленд' '641' 'идлибский'\n",
      " 'теодор' 'должок' 'пригородный' 'месседж' 'женфея' 'xj' 'lehman' 'алекно'\n",
      " 'аделина' 'гибель' 'даритель' 'пдд' 'психоаналитик' 'апатитовый'\n",
      " 'радиатор' 'джоуи' 'катыни' 'аплодировать' 'травяной' 'спецтранспорт'\n",
      " 'синоптик' 'гугл' 'легкоатлет' 'лесхоз' 'красножан' 'новолипецкий'\n",
      " 'нерегулируемый' 'кулеб' 'гемма' 'согласовываться' 'эмодзи'\n",
      " 'перевоспитание' '570' 'расчленять' 'мунтарь' 'выключатель'\n",
      " 'обличительный' 'гедонизм' 'выдыхать' 'визуальный' 'пашинян' 'праведник'\n",
      " 'чадаев' 'противоборствовать' 'братчиковый' 'трансплантация' 'откат'\n",
      " 'кабачок' 'годзюр' 'служба' 'туринский' 'попросить' 'лондонский'\n",
      " 'половой' 'полмиллиона' 'atlas' 'вводить' 'норматив' 'минобер' 'абдулаев'\n",
      " 'деми' 'александар' 'ветеринарный' 'шествовать' 'гагик' 'вылет'\n",
      " 'кинематограф' 'хоум' 'итальянка' 'борисов' 'max' 'детсад' 'макгиди'\n",
      " 'look' 'неевропейский' 'дегтярев' 'ватник' 'заставать' 'cls' 'акционизм'\n",
      " 'заполняться' 'свердловский' 'штырь' 'анализироваться' 'белорус' 'селина'\n",
      " 'пожар' 'трансформироваться' 'корешок' 'каре' 'токран' 'низменность'\n",
      " 'след' 'окампо' 'these' 'итак' 'хомуха' 'формальный' 'предстоящий'\n",
      " 'кюрасао' 'потерять' 'маунтбеттен' 'джорджио' 'genesis' 'раскаленный'\n",
      " 'дискурс' 'декодирование' 'украиноязычный' 'заработный' 'жкх' 'боярин'\n",
      " 'джанфранко' 'жиго' 'доминанта' 'некрасовка' 'перовский' 'кабальеро'\n",
      " 'озон' 'незаслуженный' 'манипулировать' 'нормализация' 'чума'\n",
      " 'кибероружие' 'credits' 'орбан' 'васил' 'дубляж' 'зарегистрироваться'\n",
      " 'тоннаж' 'шахматист' 'босвелл' 'копецки' 'правление' 'фотовыставка'\n",
      " 'осмаев' 'лаури' 'июн' 'юрист' 'умать' 'отзаявлять' 'неурегулированность'\n",
      " 'маре' 'пылиться' 'сокрытие' 'загримировывать' 'самонаведение'\n",
      " 'присуждаться' 'фальсификат' 'крок' 'florence' 'гиря' 'donald' 'раса'\n",
      " 'темария' 'имплантат' 'затылок' 'локтев' 'медпункт' 'сенегальский'\n",
      " 'донимать' 'неидеальный' 'детище' 'ковалевская' 'втретьих' 'гибрид'\n",
      " 'ютуб' 'дайан' 'birthday' 'непростительный' 'исчерпание' 'маловато'\n",
      " 'тормозить' 'танкян' 'фекалия' 'караоке' 'конуэй' 'асоциальный'\n",
      " 'обслуживающий' 'самонадеянный' 'мка' 'профессор' 'ванный' 'щеголев'\n",
      " 'deutschland' 'дион' 'южанин' 'gorilla' 'встречаться' 'рэтнер'\n",
      " 'сваривать' 'совнарком' 'step' '397' 'рогулев' 'выявляться' 'байор'\n",
      " 'иорданский' 'противоречивость' 'заз' 'муханнада' 'метанол' 'место'\n",
      " 'вскрытие' 'приватбанк' 'питтсбург' 'газоснабжение' 'подручный' 'стенд'\n",
      " 'филатов' 'неискушенный' 'татарстан' 'распил' 'контиол' 'врио' 'поручик'\n",
      " 'миккельсен' 'царствие' 'герметичный' 'минин' 'тайгер' 'токсичный'\n",
      " 'позвоночный' 'одиночный' 'обследовать' 'националь' 'госадминистрация'\n",
      " 'мерный' 'вывешивать' 'деревообрабатывающий' 'жалобщик' 'аляповатый'\n",
      " 'янкович' 'температура' 'демешин' 'свиток' 'бордюжа' 'аморальность'\n",
      " 'преследователь' 'волошин' 'бентли' 'кровля' 'хренов' 'цдр' 'баранов'\n",
      " 'лобов' 'хмеймить' 'vig' 'выполняться' 'кельтский' 'консоль'\n",
      " 'безубыточный' 'web' 'открепительный' 'отреставрировать' 'митяшин' 'лувр'\n",
      " 'бутик' 'графа' '289' 'джобс' 'арсена' 'прорываться' 'парубий'\n",
      " 'сакраментальный' 'малыгин' 'гастрономический' 'вск' 'углубление'\n",
      " 'гидрокостюм' 'доследственная' 'русенборг' '1918' 'рука' 'юлиан'\n",
      " 'водопад' 'михомайдан' 'пахмутова' 'запланировать' 'госминистр'\n",
      " 'высокобюджетный' 'свеча' 'путешественник' 'дремучий' 'леонидович'\n",
      " 'объединительный' 'активист' 'хлопать' 'заплакать' 'дзиркална' 'роксана'\n",
      " 'макаров' 'вернуть' 'послевоенный' 'тернопольский' 'маслов' 'щепка'\n",
      " 'металлоинвест' 'ивс' 'драга' 'акбулатов' 'хатчисон' 'манстер' 'вилкулы'\n",
      " 'доследственный' 'вардан' 'двойняшка' 'festival' '1740' 'хэштег'\n",
      " 'планомерный' 'трэвести' 'бурков' 'оскорбляться' 'зациклить' 'аннабель'\n",
      " 'скопировать' 'квебек' 'маккаби' 'территория' 'сизерон' 'педалировать'\n",
      " 'ливия' 'оставаться' 'мерчант' '587' 'медиакомпания' 'другоросс'\n",
      " 'электрокара' 'иоанн' 'прокатываться' 'обесценивать' 'дод' 'вовне'\n",
      " 'картография' 'железный' 'скрещивание' 'овербукинг' 'тщательно' 'потроха'\n",
      " 'оптоволоконный' 'гитлянский' 'потрудиться' 'экипаж' 'дворкович'\n",
      " 'посланец' 'перелезать' 'кипа' 'читательский' 'потупчик'\n",
      " 'снисходительность' 'диабетик' 'беспардонный' 'сборка' 'педофил' 'гван'\n",
      " 'отребье' 'запутывать' 'уолтерс' 'хорог' 'телеведущая' 'котироваться'\n",
      " 'намного' 'михайлов' 'противопоказанный' 'прерогатива' 'пункт' 'западнее'\n",
      " 'обоснованный' 'привокзальный' 'подпольщик' 'постепенно' 'билетик' 'пайк'\n",
      " 'криптобиржа' 'погладить' 'довесок' 'воеводин' 'каталонский' '382'\n",
      " 'зельдович' 'эстимейт' 'святость' 'эда' 'nirvana' 'barnes' 'нискивать'\n",
      " 'призер' 'троекратный' 'прикасаться' 'медико' 'зоркий' 'выбивать'\n",
      " 'казнокрадство' 'моторола' 'чесать' 'afp' 'снегоуборочный' 'миссисипи'\n",
      " 'wifi' 'самострой' 'мэйвезер' 'теймураз' 'неотвратимость' 'мгновение'\n",
      " 'история' 'белиз' 'страз' 'культуртрегер' 'темноволосый' 'ep' 'поэтапный'\n",
      " 'озарение' 'фнб' 'неделя' '440' 'интрига' 'пентхаус' 'зоопарк' 'x1'\n",
      " 'кныш' 'пандемия' 'янн' 'контрапункт' 'тарико' 'нск' 'медикаментозный'\n",
      " 'серафима' 'ai' 'наружность' 'грозить' 'одноразовый' 'good' 'пластинка'\n",
      " 'алхаз' 'приусадебный' 'мучитель' 'георгиос' 'ох' 'джабраил' 'хьюитт'\n",
      " 'марсианин' '777' 'фелипе' 'бедственный' 'поклониться' 'неблагоприятно'\n",
      " '2029' '75' 'киллер' 'мехико' 'переключение' 'шкиряк' 'наивный'\n",
      " 'сбываться' 'таксопарк' 'кивать' 'выносливый' 'жарков' 'портнягин'\n",
      " 'words' 'цыганский' 'задолго' 'пловчиха' 'аккомпанемент' 'клейстерс'\n",
      " 'бомж' 'марджори' 'схематичный' 'соруководитель' 'неподъемный'\n",
      " 'самоотдача' 'понятие' 'длительный' 'саутгейт' 'фсин' 'свидание'\n",
      " 'паспортный' 'манн' 'portfolio' 'осознанный' 'астон' 'тележка' 'йоханна'\n",
      " 'бульвар' 'применимый' 'муромец' 'ступать' 'боннер' 'саетов' 'флорин'\n",
      " 'дресс' 'джаспер' 'епк' 'инспекционный' 'джебхат' 'балагур'\n",
      " 'петрокоммерц' 'сечин' 'привлечение' 'ред' 'хохряков' 'столбик' 'рональд'\n",
      " 'корниленко' 'валеев' '665' 'голодовка' 'компиляция' 'мерсисайдец' '294'\n",
      " 'неприязнь' 'вкп' 'epub' 'искренность' 'самоуничтожение' 'бондарь'\n",
      " 'здоровый' 'чеченский' 'истрачивать' 'уитни' 'превращаться' 'спбгусэ'\n",
      " 'телескоп' 'прорваться' 'штаб' 'южмаш' 'алия' 'корь' 'организовывать'\n",
      " 'ромовый' 'кпд' 'тангаж' 'арн' 'распространять' 'подражатель' 'борат'\n",
      " 'присуждение' 'романо' 'принц' 'налицо' 'mgm' 'черенков' 'втб' '103'\n",
      " 'лосиный' 'тротил' 'непрофильный' 'рустэм' 'созидание' 'беренис' 'дюпуя'\n",
      " 'южный' 'цой' 'выступление' 'ватерполистка' 'пелли' 'ярослав' 'lb'\n",
      " 'неандерталец' 'горсовет' '282' 'кусок' 'нигде' 'соответствие' '937'\n",
      " 'нередкий' '349' 'пирогов' 'инхоф' 'педиатр' 'фальсификация'\n",
      " 'электричество' 'тодда' 'бркич' 'незасчитанный' 'выплывать' 'year' '271']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "сохранение каркаса мешка слов для разложения по нему вал и тест предложений\n",
    "'''\n",
    "print(np.random.permutation(train_vocabulary)[:1000])\n",
    "with open('Vocabulary.pickle', 'wb') as f:\n",
    "    pickle.dump(train_vocabulary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "disturbed-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделить предложения по текстам, а тексты по наборам X и Y\n",
    "all_tfidf_X = []\n",
    "all_tfidf_Y = []\n",
    "already_taked = 0\n",
    "for count in count_sent_in_text_X:\n",
    "    all_tfidf_X.append(tfidf_all_sent[already_taked:already_taked + count])\n",
    "    already_taked += count\n",
    "for count in count_sent_in_summ_Y:\n",
    "    all_tfidf_Y.append(tfidf_all_sent[already_taked:already_taked + count])\n",
    "    already_taked += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "contrary-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить список предложений набора Х, не разделенных на тексты, для модели\n",
    "count_sent_in_X = np.sum(count_sent_in_text_X)\n",
    "all_tfidf_X_no_text = tfidf_all_sent[:count_sent_in_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "median-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "посчитать score для каждого предложения\n",
    "сравнить каждое предложение с каждым предложением из аннотации, выбрать минимальный score\n",
    "'''\n",
    "score_all_sent = []\n",
    "for text_index in range(len(all_tfidf_X)):\n",
    "    sentences_X = all_tfidf_X[text_index].toarray()\n",
    "    sentences_Y = all_tfidf_Y[text_index].toarray()\n",
    "    for vec_x in sentences_X:\n",
    "        best_min_score = np.min([score(vec_x, vec_y) for vec_y in sentences_Y])\n",
    "        score_all_sent.append(best_min_score)\n",
    "score_all_sent = np.array(score_all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "global-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985691\n",
      "394490\n"
     ]
    }
   ],
   "source": [
    "print(len(np.array(score_all_sent)))\n",
    "print(sum(np.array(score_all_sent) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "every-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_out_train.pickle', 'wb') as f:\n",
    "    pickle.dump(all_tfidf_X_no_text, f)  # !!!отправляю не toarray(), а sparce matrix\n",
    "with open('Y_out_train.pickle', 'wb') as f:\n",
    "    pickle.dump(score_all_sent, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
